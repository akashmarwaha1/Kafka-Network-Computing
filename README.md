# Kafka-Network-Computing
## The Project shows Bigdata processing using Kafka, Docker, Ubuntu-20, Docker-compose and Spark(pyspark) MLLib Library.
---
### The data is taken from NYC Department of Finance and contains Parking Violation Tickets of NYC and its neighbouring areas.
Link - https://www.kaggle.com/new-york-city/nyc-parking-tickets

---

### Project Requirements:
Click to install softwares:
#### 1 Docker
[Windows](https://www.docker.com/products/docker-desktop) [Mac](https://hub.docker.com/editions/community/docker-ce-desktop-mac?utm_source=docker&utm_medium=webreferral&utm_campaign=dd-smartbutton&utm_location=header) [Linux](https://hub.docker.com/search?offering=community&operating_system=linux&q=&type=edition)

#### 2 Ubuntu-20 
Note- To install ubuntu on your Windows system follow the steps in the [link](https://docs.microsoft.com/en-us/windows/wsl/install-manual)

#### 3 Kafka
Use the docker compose file to install all the softwares like kafka, pyspark-jupyter notebook, Kafka-rest, zookeeper,etc.

---

Conclusion:

The data is processed in spark using pyspark.
The "kafka_pyspark_data" notebook loads the data from kafka to spark.
The "Spark_ML_Notebook_Complete" notebook process the data using K-means Machine Learning Algorithm.
